{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction to Statistical learning\n",
    "\n",
    "* Statistics is the field of study where the data can be transformed into useful information (usually in\n",
    "the form of tables, graphs, and written and verbal summaries) \n",
    "* Help to make informed policy decisions. \n",
    "* Making decisions based on Data is ubitquitous everywhere. \n",
    "* Some of the examples you might connect with are: how the BJP govt. use data from differnt platform to change the mind of voters by exposing the audience to targeted advertisements and propaganda. \n",
    "* How e-retailers such as amazon send suggestions based on your previous order, and many more. \n",
    "\n",
    "We will discuss couple of good example in our course where you will systematically understand how to get insight from data.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "<ul>\n",
    "    <li> <a href=\"#collectdata\"> Collecting Data </a> </li>\n",
    "    <li> <a href=\"#summary\"> Summary Statistics </a> </li>\n",
    "    <li> <a href=\"#covariance\"> Covariance and Correlation </a> </li>\n",
    "    <li> <a href=\"#probability\"> Simulating data using random number generator</a> </li>\n",
    "    <li> <a href=\"#hypothesis\"> Hypothesis testing </a> </li>\n",
    "    <li> <a href=\"#parameter\"> Parameter estimation </a> </li>  \n",
    "</ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Lets import all the necessary python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy import stats, polyfit\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='collectdata'></a>\n",
    "# Collecting Data\n",
    "* Input data format will be in csv or txt format\n",
    "* We will mostly use pandas library to load data for analysis \n",
    "* Once you have the dataframe loaded, you can apply various data analysis and visualization techinques to retreive useful information from data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets download diabetic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('datafiles/diabetes.data.txt', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assigment questions related to pandas data frame</font>\n",
    "\n",
    "1. Print last 20 elements of the above dataframe\n",
    "2. Print the names of all the columns in the dataframe\n",
    "3. How many rows are there in the data frame\n",
    "4. Could you extract only AGE, BMI, BP and Y columns from the data frame?\n",
    "5. Print only those rows where AGE is greater than 60\n",
    "6. Print only those rows where AGE is greater than 60 and BP is less than 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "# Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(data=df1[[\"AGE\", \"BMI\", \"BP\"]], orient=\"v\", palette=\"Set2\")\n",
    "#ax = sns.swarmplot(data=df1[[\"AGE\", \"BMI\", \"BP\"]], color=\".25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"SEX\", y=\"Y\", data=df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators; mean and variance\n",
    "\n",
    "$mean_{sample} = \\sum_{i=1}^{n} \\frac{x_{i}}{n}$\n",
    "\n",
    "$variance_{sample} = \\sum_{i=1}^{n} \\frac{(x_{i} - \\bar{x})^{2}}{n}$ (Biased)\n",
    "\n",
    "$variance_{sample} = \\sum_{i=1}^{n} \\frac{(x_{i} - \\bar{x})^{2}}{n-1}$ (Unbiased)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000  # size of population\n",
    "population = pd.Series(np.random.randint(1, 11, N))\n",
    "mean_p = population.mean()\n",
    "var_p = population.var(ddof=0)   # ((population - population.mean()) ** 2).sum() / N\n",
    "print(\"population_mean = {}, population_variance = {}\".format(mean_p, var_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {}\n",
    "n = 30  # size of each sample\n",
    "num_samples = 500 \n",
    "for i in range(num_samples):\n",
    "    samples[i] = population.sample(n).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.DataFrame(samples)\n",
    "samples.T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_s = samples.mean()\n",
    "var_s = samples.var(ddof=0)\n",
    "var_s_un = samples.var(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(figsize=(15,5))\n",
    "plt.plot(mean_s.expanding().mean())\n",
    "plt.axhline(y=mean_p, linestyle='--', color='black', label='Population mean')\n",
    "plt.xlabel('Num of samples')\n",
    "plt.ylabel('Mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(figsize=(15,5))\n",
    "plt.plot(var_s.expanding().mean(), label='Biased')\n",
    "plt.plot(var_s_un.expanding().mean(), label='UnBiased')\n",
    "plt.axhline(y=var_p, color='black', linestyle='--')\n",
    "plt.legend()\n",
    "plt.xlabel('Num of samples')\n",
    "plt.ylabel('Variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assigment questions related to summary</font>\n",
    "\n",
    "1. Returns the mean of all columns\n",
    "2. Can you find the error on mean?\n",
    "3. Returns the number of non-null values in each DataFrame column\n",
    "4. Returns the highest value in each column\n",
    "5. Returns the lowest value in each column\n",
    "6. Returns the median of each column\n",
    "7. Returns the standard deviation of each column\n",
    "8. Explain why variance is an biased estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='covariance'></a>\n",
    "# Correlation\n",
    "* It can be useful in data analysis and modeling to better understand the relationships between variables. \n",
    "* The statistical relationship between two variables is referred to as their correlation.\n",
    "* A correlation could be positive, meaning both variables move in the same direction\n",
    "* Negative, meaning that when one variable’s value increases, the other variables’ values decrease. \n",
    "* Correlation can also be neural or zero, meaning that the variables are unrelated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/correlation.png\" width=800, align=\"left\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(df1, vars=[\"AGE\", \"BMI\", \"BP\", \"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(figsize=(10,8))\n",
    "ax = sns.heatmap(corr, vmin=-1, vmax=1, annot=True, linewidths=.5, ax=axes, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assigment questions related to correlation</font>\n",
    "\n",
    "1. Draw correlation between feature between S1 and S3\n",
    "2. Could you quantify the correlation coefficent? Hint(use scipy pearson correltion function)\n",
    "3. Could you find any non linear correlation between any two fearures (just by eye)?\n",
    "4. Returns the highest value of correlation between any two features in the data set\n",
    "5. Returns the lowest value of correlation between any two features in the data set\n",
    "6. which two fearures are negatively correlated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='probability'></a>\n",
    "# Simulating data using random number generators\n",
    "A random variable is a variable whose results from the measurements of a quantity that is subject to random variations. Unlike normal mathematical variables, a random variable can take on a set of possible different values, each with an associated probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(name, nsamples):\n",
    "  if name == 'uniform':\n",
    "    dist = stats.uniform(0,2)\n",
    "  elif name == 'normal':\n",
    "    dist = stats.norm(0,1)\n",
    "  elif name == 'exponential':\n",
    "    dist = stats.expon()\n",
    "  \n",
    "  r = dist.rvs(nsamples)\n",
    "  sns.distplot(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = interactive(distribution, name=['uniform', 'normal', 'exponential'], nsamples=(0,1000,5))\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central limit theorm\n",
    "\n",
    "* The central limit theorem is one of the most important results of probability theory\n",
    "* It serves as the foundation of many methods of statistical analysis. \n",
    "* The theorem states the distribution of many sample means, known as a sampling distribution, will be normally distributed. \n",
    "* This rule holds even if the underlying distribution itself is not normally distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some random number to serve as our population\n",
    "np.random.seed(10)\n",
    "population_ages1 = np.random.normal(40,5, size=100000)\n",
    "population_ages2 = np.random.normal(60,3, size=100000)\n",
    "population_ages = np.concatenate((population_ages1, population_ages2))\n",
    "print('population mean:', np.mean(population_ages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6)\n",
    "sample_ages = np.random.choice(population_ages, size = 500)\n",
    "print('sample mean:', np.mean(sample_ages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(population_ages)\n",
    "plt.title('Population')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(sample_ages)\n",
    "plt.title('Sample')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "samples = 200\n",
    "point_estimates = [np.random.choice(population_ages, size = 500).mean()\n",
    "                   for _ in range(samples)]\n",
    "\n",
    "plt.hist(point_estimates)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampling distribution appears to be roughly normal, despite the bimodal population distribution that the samples were drawn from. In addition, the mean of the sampling distribution approaches the true population mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_ages.mean() - np.mean(point_estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assigment questions related to random number generation</font>\n",
    "\n",
    "1. Try to draw random number from binomial and poisson distribution\n",
    "2. Make a histogram (Do you see anything weird?). \n",
    "3. Try to change number of sample drawn from the population\n",
    "4. Do you see any differen between the the distrubtion?\n",
    "5. Give an example from real life where the data can be modeled as poisson distrbution and binomial distribution\n",
    "6. Difference between continuous and discrete distribution\n",
    "7. Draw any one other distrbution apart from ones we already discussed. Hint (Search on internet :))\n",
    "\n",
    "hint: use numpy random number method np.random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hypothesis'></a>\n",
    "# Hypothesis testing\n",
    "Hypothesis testing uses concepts from statistics to determine the probability that a given assumption is valid. Typically hypothesis testing starts with an assumption or an assertion about a population parameter. For example, you may be interested in validating the claim of Philips that the average life of there bulb 10 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The procedure to perform hypothesis testing is shown below (non parametric bootstrap method)\n",
    "\n",
    "* State the null hypothesis, and the statistics with which to test the statement\n",
    "* Measured the observed statistics (from the observed data). For example mean, median or something else\n",
    "* Randomly sample n data with replacement from the observed data. This means the same point may appear upto n times in one sample\n",
    "* Repeate the experiment thousands of time and store the statistics in an array\n",
    "* Figure out the fraction of time the simulated dataset give statistics equal to or greater than the measured statistics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-value\n",
    "\n",
    "In statistical hypothesis testing, the p-value or probability value or asymptotic significance is the probability for a given statistical model that, when the null hypothesis is true, the statistical summary (such as the sample mean difference between two compared groups) would be greater than or equal to the actual observed results\n",
    "\n",
    "* So if the P-value is the probability of obtaining your sample data if H0 is true, it makes sense that past a certain point, we have to concede that our null hypothesis is false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if my p_value is less than 0.05 reject the null hypothesis otherwise retain it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Null = 5. # Height\n",
    "Alternate = 6.\n",
    "std = 0.5\n",
    "fig,axes = plt.subplots(figsize=(8,6))\n",
    "x = np.random.normal(Null,std,1000)\n",
    "axes.hist(x, density=True, label='Null hypothesis distribution', histtype='step')\n",
    "plt.axvline(Alternate, color='red', label='test_statistics')\n",
    "px=np.arange(Alternate,10,0.01)\n",
    "iq=stats.norm(Null,std)\n",
    "xy = np.linspace(-3+Null, Null+3,100)\n",
    "axes.plot(xy, iq.pdf(xy), color='blue')\n",
    "axes.fill_between(px,iq.pdf(px),color='r')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.xlabel('Mean age of bulb')\n",
    "\n",
    "axes.annotate('p-value (red area)', xy=(Alternate+0.2, 0.05), xytext=(7, 0.5),\n",
    "            arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us simulate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = stats.norm(5,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - dist.cdf(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.arange(Alternate,7,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(6,0.5,10)   # height of men\n",
    "y = np.random.normal(5.3,0.6,10)  # height of women\n",
    "data = np.vstack([x,y]).transpose()\n",
    "df = pd.DataFrame(data, columns=['men', 'women'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(x) - np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy = pd.melt(df, var_name='gender', value_name='height')\n",
    "tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='gender', y='height',data=tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_parametric_bootstrap(x,f,nsim=1000, **kwargs):\n",
    "    statistics = np.zeros(nsim)\n",
    "    for i in range(nsim):\n",
    "        indices = np.random.randint(0,len(x),len(x))\n",
    "        X = x[indices]\n",
    "        statistics[i] = f(X, **kwargs)\n",
    "        \n",
    "    return statistics\n",
    "\n",
    "def confidence_interval(samples, interval=95):\n",
    "    alpha = (100 - interval) / 2\n",
    "    lower = alpha\n",
    "    upper = 100 - alpha\n",
    "    left = np.percentile(samples, lower)\n",
    "    right = np.percentile(samples, upper)\n",
    "    #print(\"[{:.3f}, {:.3f}]\".format(left,right))\n",
    "    return left, right\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh = tidy[tidy.gender =='men'].height.values\n",
    "wh = tidy[tidy.gender =='women'].height.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanx = non_parametric_bootstrap(mh, np.mean)\n",
    "meany = non_parametric_bootstrap(wh, np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(meanx, label='Bootstrap Mean Men')\n",
    "sns.distplot(meany, label='Bootstrap Mean Women')\n",
    "plt.hlines(y=0, xmin = confidence_interval(meanx, 68)[0], xmax = confidence_interval(meanx,68)[1], linewidth=6,color='b')\n",
    "plt.hlines(y=0, xmin = confidence_interval(meany,68)[0], xmax = confidence_interval(meany,68)[1], linewidth=6, color='r')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.xlabel('Mean values')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = np.array([5,4,6,7])\n",
    "resample(gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(wh,mh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_of_means(x,y):\n",
    "    return np.mean(y) -  np.mean(x)\n",
    "\n",
    "def test_null(x,y, iters = 1000):\n",
    "    new = np.concatenate([x,y])\n",
    "    means_diff = np.zeros(iters)\n",
    "    for i in range(iters):\n",
    "        resample_data = resample(new)\n",
    "        xx, yy = resample_data[:len(x)], resample_data[len(x):]\n",
    "        means_diff[i] = difference_of_means(xx,yy)\n",
    "        \n",
    "        \n",
    "    return means_diff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_of_mean = test_null(wh,mh)\n",
    "pvalue = difference_of_means(wh,mh)\n",
    "print(\"test pvalue = {}\".format(pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(diff_of_mean)\n",
    "    \n",
    "plt.title('Bootstrapped differece in sample means')\n",
    "plt.xlabel('Differece in means')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.axvline(pvalue, color='red')\n",
    "#plt.legend()\n",
    "p_value = np.sum(diff_of_mean > pvalue) / len(diff_of_mean)\n",
    "print(\"The p-value for these samples is {:.2g}\".format(p_value))\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print('We can reject the null hypothesis that mean height of men and women are equal')\n",
    "else:\n",
    "    print('We can not reject the null hypothesis that mean height of men and women are equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theoretical_pvalue = stats.mannwhitneyu(wh,mh)[1]\n",
    "print('Theoretical value for the p-value = {:.2g}'.format(theoretical_pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assigment problems related to hypothesis testing</font>\n",
    "1. Lets say my null hypothesis is that there is no correlation between feature S1 and S3 in the diabetic data sets. Will you reject the null hypothesis or not \n",
    "2. How will you quantify the statement\n",
    "3. Bonus point if you test the same thing with bootstrap method (Below is the example)\n",
    "\n",
    "hint: Use scipy.stats.pearsonr to quantify the hypothesis statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coin toss hpothesis test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_hypothesis = 0.5\n",
    "alternate_hypothesis = 0.55\n",
    "n_coins = 20\n",
    "data = np.random.binomial(n_coins,alternate_hypothesis,size=100)\n",
    "print(\"Mean number of heads appear in simulated data = {}\".format(np.mean(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shited_mean = data - np.mean(data) + (null_hypothesis * n_coins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coin_samping (data, samples = 10000):\n",
    "    boot_sample = np.zeros(samples)\n",
    "    for i in range(samples):\n",
    "        resample_data = np.mean(resample(data))\n",
    "        boot_sample[i] = resample_data \n",
    "    return boot_sample\n",
    "\n",
    "sample_coin = coin_samping(shited_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(sample_coin, bins=15)\n",
    "\n",
    "plt.axvline(np.mean(data), color='red', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Probability of head')\n",
    "plt.ylabel('Probability density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Probability = np.sum(sample_coin >= np.mean(data)) / len(sample_coin)\n",
    "print(\"Probability to get at least {} heads by chance is {} if the null hypothesis \\\n",
    "is true \".format(np.mean(data), Probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Theoretical estimate\n",
    "print(\"theoretical estimate {}\".format(stats.ttest_1samp(data, null_hypothesis*n_coins)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assgiment problem 1 in 7.2 section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets load the data\n",
    "X = df1[[\"S1\", \"S3\"]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "def bootstrap_sampling (dataframe, samples = 10000):\n",
    "    boot_sample = []\n",
    "    data = dataframe.to_numpy()\n",
    "    for i in range(samples):\n",
    "        resample_data = resample(data, n_samples=data.shape[0])\n",
    "        corr = stats.pearsonr(resample_data[:,0], resample_data[:,1])[0]\n",
    "        boot_sample.append(corr)\n",
    "    return np.array(boot_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = bootstrap_sampling(X)\n",
    "print(\"mean={:.3f}, standard deviation={:.3f}\".format(np.mean(samples), np.std(samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_confidence_interval_endpoint = np.percentile(samples, 2.5)\n",
    "right_confidence_interval_endpoint = np.percentile(samples, 97.5)\n",
    "ax = sns.distplot(samples)\n",
    "plt.axvline(left_confidence_interval_endpoint, color='red', alpha=0.5)\n",
    "plt.axvline(right_confidence_interval_endpoint, color='red', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = stats.pearsonr(X.to_numpy()[:,0], X.to_numpy()[:,1])[0]\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_corr = 0\n",
    "left_tail = 0\n",
    "right_tail = 2 * np.mean(samples)\n",
    "prob = np.sum(samples <= left_tail ) / 10000 + np.sum(samples >= right_tail ) / 10000\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(X.to_numpy()[:,0], X.to_numpy()[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='parameter'></a>\n",
    "# Parameter estimation\n",
    "Parameter estimates (also called coefficients) are the change in the response associated with a one-unit change of the predictor, all other predictors being held constant\n",
    "\n",
    "$y = slope * x + intercept$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept = np.polyfit(df1['BMI'], df1['Y'], 1)\n",
    "print(\"slope={:.2g}, intercept={:.2f}\".format(slope, intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = np.min(df1['BMI']), np.max(df1['BMI'])\n",
    "x = np.linspace(x_min-5,x_max+5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(figsize=(8,8))\n",
    "plt.plot(df1['BMI'], df1['Y'], marker='o', linestyle='none', label='Data')\n",
    "plt.plot(x, x*slope + intercept, label=\"slope={:.2g}, intercept={:.2f}\".format(slope, intercept))\n",
    "plt.legend()\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Target variable(Y)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assigment related to parameter estimation (problem)</font>\n",
    "1. Instead of using BMI, try to see how the Y varies with S5, S3 variable in the diabetic dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
